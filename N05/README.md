[![GitHub watchers](https://img.shields.io/badge/tulip--lab-Open--Projects-brightgreen)](../README.md)
[![GitHub watchers](https://img.shields.io/badge/Module-NEXUS-orange)](README.md)

# `NEXUS` Data Distillation

Data distillation, an emerging technique within the broader field of data compression and model training, aims to create compact, informative representations of large datasets. This process not only reduces storage and computational demands but also potentially enhances model performance by focusing on the most salient features of the data. The incorporation of causal relationship analysis into data distillation represents an innovative approach, promising to maintain or even improve the predictive power of models trained on distilled datasets by preserving the underlying causal structures of the data.

### :notebook_with_decorative_cover: `NEXUS-S1`

The related documents are encrypted, and you will receive the password upon the acceptance into stage :one: of the project. 

- [NEXUS-S1 Guideline](https://github.com/tulip-lab/handouts/blob/main/nexus/Nexus-S1.pdf) 
- [Stage 1 - N05: Data Distillation](https://github.com/tulip-lab/handouts/blob/main/nexus/N01-S1.pdf) 

##### Outstanding Student Works

- TO BE ADDED

### :notebook_with_decorative_cover: `NEXUS-S2`

The related documents are encrypted, and you will receive the password upon the acceptance into the stage :two: of the project. 

- [NEXUS-S2 Guideline](https://github.com/tulip-lab/handouts/blob/main/nexus/Nexus-S2.pdf) 
- [Stage 2 - N05: Data Distillation](https://github.com/tulip-lab/handouts/blob/main/nexus/N01-S2.pdf) 

##### Outstanding Student Works

- TO BE ADDED


### :notebook_with_decorative_cover: `NEXUS-S3`


The related documents are encrypted, and you will receive the password upon the acceptance into the stage :three: of the project. 

- [NEXUS-S3 Guideline](https://github.com/tulip-lab/handouts/blob/main/nexus/Nexus-S3.pdf) 
- [Stage 3 - N05: Data Distillation](https://github.com/tulip-lab/handouts/blob/main/nexus/N01-S3.pdf) 

##### Outstanding Student Works

- TO BE ADDED
